# Flex Attention Implementation in MLX

This project demonstrates the implementation of Flex Attention using the MLX framework. 

Flex Attention is an efficient attention mechanism designed to reduce memory usage and computational overhead, 
making it suitable for large-scale models and long sequences.
